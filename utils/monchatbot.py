import random  # Pour g√©n√©rer des r√©ponses humaines al√©atoires (emojis, expressions)
import torch  # Utilis√© pour les tenseurs avec sentence-transformers
from sentence_transformers import util  # Pour le calcul de similarit√© cosinus entre embeddings

# Import des fonctions de recherche externe
from utils.wikipedia_search import get_wikipedia_summary  # Fonction de recherche dans Wikip√©dia
from utils.google_search import recherche_google  # Fonction de recherche via l'API Google

# Import du mod√®le de transformation de texte en vecteur
from utils.neural_net import model  # SentenceTransformer charg√© ailleurs (BERT ou autre)

# Import de constantes de configuration
from app.config import WIKI_TRIGGER, TAILLE_MAX  # D√©clencheur Wikipedia + taille max de m√©moire

# Import du mod√®le g√©n√©ratif personnalis√© (type GPT)
from .neogpt import NeoGPT

# Cr√©ation d'une instance de NeoGPT avec une personnalit√© d√©finie
neo_gpt = NeoGPT(personality="assistant")

# Variable globale pour stocker les embeddings des questions pr√©c√©dentes
corpus_embeddings = None

# Fonction qui met √† jour les embeddings du corpus m√©moire
def update_corpus_embeddings():
    from app.memory import memoire_cache, lock  # Import de la m√©moire + verrou de thread
    global corpus_embeddings
    with lock:  # S√©curise l'acc√®s multi-thread
        questions = [item["question"] for item in memoire_cache]  # On r√©cup√®re toutes les questions m√©moris√©es
        # Encode les questions si elles existent
        corpus_embeddings = model.encode(questions, convert_to_tensor=True) if questions else None

# Mise √† jour initiale des embeddings
update_corpus_embeddings()

# Fonction pour humaniser les r√©ponses avec des expressions al√©atoires
def ton_humain_reponse(texte: str) -> str:
    r√©actions = (
        ["üòä", "üëç", "√áa me fait plaisir de t'aider !", "Super question !", "Tu es brillant(e) !"],  # Amical
        ["Hmm...", "Int√©ressant...", "Voyons voir...", "C'est une bonne question.", "Je r√©fl√©chis..."],  # Neutre
        ["Je ne suis pas une boule de cristal, mais je crois que c'est √ßa ! üòÇ",
         "Si j'avais un euro √† chaque fois qu'on me pose cette question... üí∏",
         "Je suis un bot, mais je commence √† comprendre les humains ! ü§ñ",
         "Je suis pas parfait, mais j'essaie ! üòÖ"]  # Humour
    )
    r = random.random()
    # Choix du ton bas√© sur une probabilit√©
    prefix = random.choice(
        r√©actions[0] if r < 0.15 else r√©actions[2] if r < 0.2 else r√©actions[1]
    )
    return f"{prefix} {texte}"  # Ajoute un pr√©fixe expressif √† la r√©ponse

# D√©tection des salutations ou formules de politesse dans les messages
def detect_salutation(message: str) -> str | None:
    msg = message.lower()
    # Si message contient un mot de salutation
    if any(greet in msg for greet in ["bonjour", "salut", "coucou", "hello", "hey"]):
        return random.choice([
            "Bonjour ! Comment puis-je t'aider aujourd'hui ?",
            "Salut ! Ravi de te voir.",
            "Coucou ! Que puis-je faire pour toi ?"
        ])
    
    # Si message contient une question de type "√ßa va ?"
    if any(x in msg for x in ["comment vas-tu", "comment √ßa va", "√ßa va", "tu vas bien"]):
        return random.choice([
            "Je vais tr√®s bien, merci ! Et toi ?",
            "Tout roule ici, pr√™t √† t'aider !",
            "Super bien, merci de demander !"
        ])
    
    if any(x in msg for x in ["merci", "merci beaucoup", "merci bien"]):
        return random.choice([
            "Avec plaisir ! Si tu as d'autres questions, n'h√©site pas.",
            "C'est toujours un plaisir de t'aider !",
            "Merci √† toi pour ta question !"
        ])
    
    if any(x in msg for x in ["au revoir", "√† bient√¥t", "√† la prochaine"]):
        return random.choice([
            "Au revoir ! √Ä bient√¥t j'esp√®re !",
            "√Ä la prochaine ! Prends soin de toi.",
            "Merci d'avoir discut√© avec moi, √† bient√¥t !"
        ])
    
    if any(x in msg for x in ["s'il te pla√Æt", "svp", "stp"]):
        return random.choice([
            "Bien s√ªr, je suis l√† pour √ßa !",
            "Pas de souci, je suis l√† pour t'aider !",
            "Avec plaisir, que puis-je faire pour toi ?"
        ])
    
    if any(x in msg for x in ["oui", "non", "peut-√™tre", "d'accord"]):
        return random.choice([
            "D'accord, je prends note !",
            "Bien compris, merci pour ta r√©ponse !",
            "Merci pour ta r√©ponse, je suis l√† si tu as d'autres questions !"
        ])
    
    if any(x in msg for x in ["je ne sais pas", "je ne comprends pas", "je ne suis pas s√ªr"]):
        return random.choice([
            "Pas de souci, je suis l√† pour t'aider √† comprendre !",
            "C'est normal, on peut en discuter ensemble.",
            "Pas de probl√®me, je peux t'expliquer si tu veux !"
        ])
    
    if any(x in msg for x in ["j'ai besoin d'aide", "aide moi", "peux-tu m'aider"]):
        return random.choice([
            "Bien s√ªr, je suis l√† pour √ßa ! Que puis-je faire pour toi ?",
            "Pas de souci, je suis l√† pour t'aider !",
            "Dis-moi ce dont tu as besoin, je vais essayer de t'aider."
        ])
    return None  # Pas de salutation d√©tect√©e

# Ajoute une nouvelle question/r√©ponse √† la m√©moire et met √† jour les embeddings
def ajouter_a_memoire(question: str, reponse: str):
    from app.memory import memoire_cache, lock, save_memory
    with lock:
        memoire_cache.append({"question": question, "response": reponse})  # Ajout
        if len(memoire_cache) > TAILLE_MAX:  # On respecte la taille max
            memoire_cache.pop(0)
        save_memory()  # Sauvegarde sur disque
        update_corpus_embeddings()  # Met √† jour les vecteurs

# Fonction principale qui g√®re une requ√™te utilisateur
def obtenir_la_response(message: str) -> str:
    from app.memory import memoire_cache, lock

    msg = message.strip()  # Nettoyage
    if not msg:
        return "Je n'ai pas bien saisi ta question, pourrais-tu reformuler s'il te pla√Æt ?"

    # Si message est une salutation, on r√©pond directement
    if (resp := detect_salutation(msg)):
        return resp

    # Si l'utilisateur veut une recherche Wikip√©dia
    if msg.lower().startswith(WIKI_TRIGGER):
        query = msg[len(WIKI_TRIGGER):].strip()
        if not query:
            return "Tu dois me dire ce que tu veux que je cherche sur Wikip√©dia."
        try:
            if (res := get_wikipedia_summary(query)):
                return ton_humain_reponse(f"Voici ce que j'ai trouv√© sur Wikip√©dia :\n{res}")
            return ton_humain_reponse("D√©sol√©, rien trouv√© de pertinent sur Wikip√©dia.")
        except Exception as e:
            return ton_humain_reponse(f"Erreur lors de la recherche Wikip√©dia : {e}")

    # Encodage de la requ√™te utilisateur
    try:
        embedding = model.encode(msg, convert_to_tensor=True)
    except Exception as e:
        return ton_humain_reponse(f"Erreur lors de l'encodage de la question : {e}")

    global corpus_embeddings
    with lock:
        # Si m√©moire vide, on enregistre simplement
        if not memoire_cache:
            ajouter_a_memoire(msg, "Je vais m'en souvenir pour la prochaine fois.")
            return ton_humain_reponse(f"C'est la premi√®re fois que tu me poses √ßa, je retiens : ¬´ {msg} ¬ª")

        # Si des embeddings sont pr√©sents, on cherche une r√©ponse similaire
        if corpus_embeddings is not None:
            try:
                scores = util.cos_sim(embedding, corpus_embeddings)[0]  # Similarit√© cosinus
                idx = int(scores.argmax())  # Meilleur score
                max_score = float(scores[idx])

                # Seuil dynamique bas√© sur la taille de la m√©moire
                seuil = 0.55 if len(memoire_cache) < 10 else 0.60 if len(memoire_cache) < 50 else 0.65
                if max_score >= seuil:
                    return ton_humain_reponse(f"Je pense que ceci r√©pond √† ta question :\n{memoire_cache[idx]['response']}")
            except Exception as e:
                return ton_humain_reponse(f"Erreur lors de la recherche dans la m√©moire : {e}")

    # Si pas de match en m√©moire, on essaie une g√©n√©ration via NeoGPT
    try:
        res = neo_gpt.chat(msg, max_length=100)
        ajouter_a_memoire(msg, res)
        return ton_humain_reponse(res)
    except Exception as e:
        # Si NeoGPT √©choue, on tente Google en fallback
        try:
            if (res := recherche_google(msg)):
                ajouter_a_memoire(msg, res)
                return ton_humain_reponse(f"Voici ce que j'ai trouv√© via Google :\n{res}")
        except Exception as e2:
            return ton_humain_reponse(f"Erreur lors de la recherche Google : {e2}")
        return ton_humain_reponse(f"Erreur interne lors de la g√©n√©ration de r√©ponse : {e}")

    # Fallback ultime : on garde la question et on promet d'y revenir
    ajouter_a_memoire(msg, "Je vais m'en souvenir pour la prochaine fois.")
    return ton_humain_reponse("Je ne connais pas encore la r√©ponse, mais je l'apprendrai pour toi !")
